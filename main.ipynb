{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f945b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/26 15:23:27 INFO mlflow.tracking.fluent: Experiment with name 'CatBoost_TimeSeries_Optuna' does not exist. Creating a new experiment.\n",
      "/tmp/ipykernel_10420/1897038504.py:118: ExperimentalWarning: MLflowCallback is experimental (supported from v1.4.0). The interface can change in the future.\n",
      "  mlcb  = MLflowCallback(metric_name=\"val_rmse\",\n",
      "/tmp/ipykernel_10420/1897038504.py:122: ExperimentalWarning: track_in_mlflow is experimental (supported from v2.9.0). The interface can change in the future.\n",
      "  @mlcb.track_in_mlflow()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 165\u001b[39m\n\u001b[32m    157\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mean_rmse\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run(run_name=\u001b[33m\"\u001b[39m\u001b[33moptuna_catboost\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# static HW snapshot\u001b[39;00m\n\u001b[32m    161\u001b[39m     mlflow.log_params({\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcpu_cores\u001b[39m\u001b[33m\"\u001b[39m: psutil.cpu_count(logical=\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmem_total_gb\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(psutil.virtual_memory().total / \u001b[32m2\u001b[39m**\u001b[32m30\u001b[39m, \u001b[32m2\u001b[39m),\n\u001b[32m    164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgpu_name\u001b[39m\u001b[33m\"\u001b[39m: (\u001b[43mpynvml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnvmlDeviceGetName\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpynvml\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnvmlDeviceGetHandleByIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m()\n\u001b[32m    166\u001b[39m                      \u001b[38;5;28;01mif\u001b[39;00m pynvml.nvmlInit() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNA\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    167\u001b[39m     })\n\u001b[32m    168\u001b[39m     study = optuna.create_study(direction=\u001b[33m\"\u001b[39m\u001b[33mminimize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    169\u001b[39m                                 sampler=optuna.samplers.TPESampler(seed=SEED))\n\u001b[32m    170\u001b[39m     study.optimize(objective, n_trials=N_TRIALS, callbacks=[mlcb])\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "import gc, random, psutil, pynvml, polars as pl, numpy as np, optuna, mlflow, mlflow.catboost\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "\n",
    "# ────────────────────────────────────  CONFIG  ─────────────────────────────────── #\n",
    "SEED          = 42\n",
    "DATA_DIR      = Path(\"data\")          # <- full 12-month parquet set\n",
    "TARGET        = \"tip_amount\"\n",
    "N_TRIALS      = 50\n",
    "N_SPLITS      = 5\n",
    "MAX_ITERS     = 10_000\n",
    "EARLY_STOP    = 100\n",
    "EXPERIMENT    = \"CatBoost_TimeSeries_Optuna\"\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ───────────────────────────────  HELPER: SYS METRICS  ─────────────────────────── #\n",
    "def log_sys(prefix: str = \"\") -> None:\n",
    "    mlflow.log_metric(f\"{prefix}cpu_pct\",   psutil.cpu_percent())\n",
    "    mlflow.log_metric(f\"{prefix}mem_pct\",   psutil.virtual_memory().percent)\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        h = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "        u = pynvml.nvmlDeviceGetUtilizationRates(h)\n",
    "        m = pynvml.nvmlDeviceGetMemoryInfo(h)\n",
    "        mlflow.log_metric(f\"{prefix}gpu_util_pct\",      u.gpu)\n",
    "        mlflow.log_metric(f\"{prefix}gpu_mem_used_mb\",   m.used / 2**20)\n",
    "        pynvml.nvmlShutdown()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# ───────────────────────────────  DATA  PIPELINE  ─────────────────────────────── #\n",
    "def load_one(parquet_file: Path) -> pl.DataFrame:\n",
    "    df = pl.read_parquet(parquet_file, low_memory=True)\n",
    "\n",
    "    # unify datetime precision ────────────────────────────────────────────\n",
    "    for col in (\"tpep_pickup_datetime\", \"pickup_datetime\",\n",
    "                \"tpep_dropoff_datetime\", \"dropoff_datetime\"):\n",
    "        if col in df.columns:\n",
    "            df = df.with_columns(pl.col(col).cast(pl.Datetime(\"ns\")))\n",
    "\n",
    "    # remove negative targets\n",
    "    df = df.filter(pl.col(TARGET) >= 0)\n",
    "\n",
    "    # trip duration + calendar features ───────────────────────────────────\n",
    "    ns = 60_000_000_000\n",
    "    pick = next((c for c in (\"tpep_pickup_datetime\", \"pickup_datetime\") if c in df.columns), None)\n",
    "    drop = next((c for c in (\"tpep_dropoff_datetime\", \"dropoff_datetime\") if c in df.columns), None)\n",
    "\n",
    "    if pick and drop:\n",
    "        df = (\n",
    "            df\n",
    "            .with_columns((\n",
    "                (pl.col(drop).cast(pl.Int64) - pl.col(pick).cast(pl.Int64)) / ns\n",
    "            ).cast(pl.Float32).alias(\"trip_duration_min\"))\n",
    "            .with_columns([\n",
    "                pl.col(pick).dt.month().cast(pl.Int8).alias(\"pickup_month\"),\n",
    "                pl.col(pick).dt.day().cast(pl.Int8).alias(\"pickup_day\"),\n",
    "                pl.col(pick).dt.hour().cast(pl.Int8).alias(\"pickup_hour\"),\n",
    "                pl.col(pick).dt.weekday().cast(pl.Int8).alias(\"pickup_dow\"),\n",
    "            ])\n",
    "            .drop([pick, drop])\n",
    "        )\n",
    "    else:   # fallback for rare corrupt rows\n",
    "        df = df.with_columns([\n",
    "            pl.lit(0).cast(pl.Float32).alias(\"trip_duration_min\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_month\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_day\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_hour\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_dow\"),\n",
    "        ])\n",
    "\n",
    "    # guarantee existence of every fee column (missing for early months)\n",
    "    for c, t in {\n",
    "        \"cbd_congestion_fee\": pl.Float32,\n",
    "        \"airport_fee\":        pl.Float32,\n",
    "        \"congestion_surcharge\": pl.Float32,\n",
    "    }.items():\n",
    "        if c not in df.columns:\n",
    "            df = df.with_columns(pl.lit(0).cast(t).alias(c))\n",
    "\n",
    "    # categorical handling ────────────────────────────────────────────────\n",
    "    int_cats   = [\"VendorID\",\"RatecodeID\",\"PULocationID\",\"DOLocationID\",\n",
    "                  \"payment_type\",\"pickup_month\",\"pickup_day\",\"pickup_hour\",\"pickup_dow\"]\n",
    "    str_cats   = [\"store_and_fwd_flag\"]\n",
    "\n",
    "    for c in int_cats:\n",
    "        if c not in df.columns:\n",
    "            df = df.with_columns(pl.lit(-1).cast(pl.Int32).alias(c))\n",
    "        else:\n",
    "            df = df.with_columns(pl.col(c).cast(pl.Int32))\n",
    "\n",
    "    for c in str_cats:                 # only *string* categoricals to Categorical\n",
    "        if c not in df.columns:\n",
    "            df = df.with_columns(pl.lit(\"missing\").cast(pl.Utf8).alias(c))\n",
    "        df = df.with_columns(pl.col(c).cast(pl.Categorical))\n",
    "\n",
    "    return df\n",
    "\n",
    "frames = [load_one(f) for f in sorted(DATA_DIR.glob(\"*.parquet\"))]\n",
    "df = pl.concat(frames)\n",
    "del frames; gc.collect()\n",
    "\n",
    "pdf   = df.to_pandas(use_pyarrow_extension_array=True)\n",
    "y     = pdf[TARGET]\n",
    "X     = pdf.drop(columns=[TARGET])\n",
    "cat_cols = [c for c in [\"store_and_fwd_flag\"]  # only the real string category\n",
    "            if c in X.columns]\n",
    "\n",
    "# ──────────────────  OPTUNA + MLFLOW  ────────────────── #\n",
    "tscv  = TimeSeriesSplit(n_splits=N_SPLITS)\n",
    "mlflow.set_experiment(EXPERIMENT)\n",
    "\n",
    "mlcb  = MLflowCallback(metric_name=\"val_rmse\",\n",
    "                       create_experiment=False,\n",
    "                       mlflow_kwargs={\"nested\": True})\n",
    "\n",
    "@mlcb.track_in_mlflow()\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"depth\":              trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"learning_rate\":      trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"l2_leaf_reg\":        trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10,  log=True),\n",
    "        \"subsample\":          trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"colsample_bylevel\":  trial.suggest_float(\"colsample_bylevel\", 0.5, 1.0),\n",
    "        \"min_data_in_leaf\":   trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        \"iterations\":         MAX_ITERS,\n",
    "        \"early_stopping_rounds\": EARLY_STOP,\n",
    "        \"eval_metric\":        \"RMSE\",\n",
    "        \"random_seed\":        SEED,\n",
    "        \"task_type\":          \"GPU\",\n",
    "        \"verbose\":            0,\n",
    "        \"cat_features\":       cat_cols,\n",
    "    }\n",
    "\n",
    "    cv_rmse, best_iters = [], []\n",
    "    for tr, vl in tscv.split(X):\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X.iloc[tr], y.iloc[tr],\n",
    "                  eval_set=(X.iloc[vl], y.iloc[vl]),\n",
    "                  verbose=False)\n",
    "        cv_rmse.append(mean_squared_error(y.iloc[vl],\n",
    "                                          model.predict(X.iloc[vl]),\n",
    "                                          squared=False))\n",
    "        best_iters.append(model.get_best_iteration())\n",
    "        del model; gc.collect()\n",
    "\n",
    "    mean_rmse = float(np.mean(cv_rmse))\n",
    "    trial.set_user_attr(\"best_iterations\", int(np.mean(best_iters)))\n",
    "    mlflow.log_metric(\"rmse_cv\", mean_rmse)\n",
    "    mlflow.log_metric(\"best_iterations\", trial.user_attrs[\"best_iterations\"])\n",
    "    log_sys()\n",
    "    return mean_rmse\n",
    "\n",
    "with mlflow.start_run(run_name=\"optuna_catboost\"):\n",
    "    # static HW snapshot\n",
    "    mlflow.log_params({\n",
    "        \"cpu_cores\": psutil.cpu_count(logical=True),\n",
    "        \"mem_total_gb\": round(psutil.virtual_memory().total / 2**30, 2),\n",
    "        \"gpu_name\": (pynvml.nvmlDeviceGetName(\n",
    "                        pynvml.nvmlDeviceGetHandleByIndex(0)).decode()\n",
    "                     if pynvml.nvmlInit() is None else \"NA\")\n",
    "    })\n",
    "    study = optuna.create_study(direction=\"minimize\",\n",
    "                                sampler=optuna.samplers.TPESampler(seed=SEED))\n",
    "    study.optimize(objective, n_trials=N_TRIALS, callbacks=[mlcb])\n",
    "\n",
    "    best_params = study.best_trial.params\n",
    "    final_iter  = study.best_trial.user_attrs[\"best_iterations\"]\n",
    "\n",
    "    final = {\n",
    "        **best_params,\n",
    "        \"iterations\": final_iter,\n",
    "        \"random_seed\": SEED,\n",
    "        \"task_type\": \"GPU\",\n",
    "        \"verbose\": 0,\n",
    "        \"cat_features\": cat_cols,\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**final)\n",
    "    model.fit(X, y, verbose=False)\n",
    "    mlflow.log_params(final)\n",
    "    mlflow.catboost.log_model(model, artifact_path=\"model\")\n",
    "    log_sys(\"final_\")\n",
    "\n",
    "print(f\"Best CV RMSE: {study.best_value:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6))\n",
    "# sns.scatterplot(x=y_test, y=preds, alpha=0.3)\n",
    "# plt.xlabel(\"Actual\")\n",
    "# plt.ylabel(\"Predicted\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"scatter_actual_vs_pred.png\", dpi=300)\n",
    "\n",
    "# residuals = y_test - preds\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.histplot(residuals, bins=100, kde=True)\n",
    "# plt.xlabel(\"Residuals\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"residual_hist.png\", dpi=300)\n",
    "\n",
    "# importances = model.get_feature_importance(type=\"PredictionValuesChange\")\n",
    "# imp_df = pd.DataFrame({\"feature\": features, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.barplot(x=\"importance\", y=\"feature\", data=imp_df.head(20))\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"feature_importance.png\", dpi=300)\n",
    "\n",
    "# model.save_model(\"tip_model_catboost.cbm\")\n",
    "# imp_df.to_csv(\"feature_importance.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pad-final-project-uFfiJNJD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
