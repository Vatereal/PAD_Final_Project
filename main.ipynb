{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a643b0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "import argparse\n",
    "import pathlib\n",
    "import urllib.request\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import pathlib\n",
    "import glob\n",
    "import pyarrow.dataset as ds\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bab5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxiDataset(Dataset):\n",
    "    def __init__(self, df, cont_cols, cat_cols, scaler=None):\n",
    "        self.cont = df[cont_cols].values.astype(np.float32)\n",
    "        if scaler is not None:\n",
    "            self.cont = scaler.transform(self.cont)\n",
    "        self.cats = df[cat_cols].astype(\"category\")\n",
    "        self.cat_codes = np.stack([self.cats[col].cat.codes.values for col in cat_cols], 1).astype(np.int64)\n",
    "        self.y = df[\"tips\"].values.astype(np.float32)\n",
    "        self.cardinalities = [len(self.cats[col].cat.categories) for col in cat_cols]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cont[idx], self.cat_codes[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a725d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipModel(nn.Module):\n",
    "    def __init__(self, cat_cardinalities, cont_dim, hidden_sizes=(128, 64, 32), emb_rule=lambda c: min(50, (c + 1) // 2)):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleList([nn.Embedding(card, emb_rule(card)) for card in cat_cardinalities])\n",
    "        emb_dim = sum(e.embedding_dim for e in self.embeddings)\n",
    "        layers = []\n",
    "        dims = [cont_dim + emb_dim] + list(hidden_sizes)\n",
    "        for i in range(len(dims) - 1):\n",
    "            layers.extend([\n",
    "                nn.Linear(dims[i], dims[i + 1]),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm1d(dims[i + 1]),\n",
    "                nn.Dropout(0.2),\n",
    "            ])\n",
    "        layers.append(nn.Linear(dims[-1], 1))\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, cont, cats):\n",
    "        emb_outs = [emb(cats[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x = torch.cat(emb_outs + [cont], dim=1)\n",
    "        return self.mlp(x).squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedc8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--data-dir DATA_DIR]\n",
      "                             [--sample-frac SAMPLE_FRAC] [--epochs EPOCHS]\n",
      "                             [--batch-size BATCH_SIZE] [--lr LR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/run/user/1000/jupyter/runtime/kernel-v328e87f0fff34ba946b6f85f751444f2a033c68ce.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vatereal/.cache/pypoetry/virtualenvs/pad-final-project-uFfiJNJD-py3.12/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "import glob\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TaxiDataset(Dataset):\n",
    "    def __init__(self, df, cont_cols, cat_cols, scaler=None):\n",
    "        self.cont = df[cont_cols].values.astype(np.float32)\n",
    "        if scaler is not None:\n",
    "            self.cont = scaler.transform(self.cont)\n",
    "        cats = df[cat_cols].astype(\"category\")\n",
    "        self.cat_codes = np.stack([cats[c].cat.codes.values for c in cat_cols], 1).astype(np.int64)\n",
    "        self.y = df[\"tips\"].values.astype(np.float32)\n",
    "        self.cardinalities = [len(cats[c].cat.categories) for c in cat_cols]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cont[idx], self.cat_codes[idx], self.y[idx]\n",
    "\n",
    "\n",
    "class TipModel(nn.Module):\n",
    "    def __init__(self, cat_cardinalities, cont_dim, hidden=(128, 64, 32), emb_rule=lambda c: min(50, (c + 1) // 2)):\n",
    "        super().__init__()\n",
    "        self.emb = nn.ModuleList([nn.Embedding(card, emb_rule(card)) for card in cat_cardinalities])\n",
    "        xdim = cont_dim + sum(e.embedding_dim for e in self.emb)\n",
    "        layers = []\n",
    "        dims = [xdim] + list(hidden)\n",
    "        for a, b in zip(dims, dims[1:]):\n",
    "            layers += [nn.Linear(a, b), nn.ReLU(), nn.BatchNorm1d(b), nn.Dropout(0.2)]\n",
    "        layers += [nn.Linear(dims[-1], 1)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, cont, cats):\n",
    "        z = torch.cat([e(cats[:, i]) for i, e in enumerate(self.emb)] + [cont], 1)\n",
    "        return self.net(z).squeeze(1)\n",
    "\n",
    "\n",
    "def list_files(data_dir: pathlib.Path) -> list[pathlib.Path]:\n",
    "    pat = str(data_dir / \"fhvhv_tripdata_*.parquet\")\n",
    "    return [pathlib.Path(p) for p in sorted(glob.glob(pat))]\n",
    "\n",
    "\n",
    "def preprocess(paths, sample=0.2):\n",
    "    cols = [\n",
    "        \"pickup_datetime\",\n",
    "        \"dropoff_datetime\",\n",
    "        \"trip_miles\",\n",
    "        \"trip_time\",\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"hvfhs_license_num\",\n",
    "        \"dispatching_base_num\",\n",
    "        \"shared_request_flag\",\n",
    "        \"wav_request_flag\",\n",
    "        \"base_passenger_fare\",\n",
    "        \"tolls\",\n",
    "        \"bcf\",\n",
    "        \"sales_tax\",\n",
    "        \"congestion_surcharge\",\n",
    "        \"tips\",\n",
    "    ]\n",
    "    table = ds.dataset([str(p) for p in paths], format=\"parquet\").to_table(columns=cols)\n",
    "    df = table.to_pandas()\n",
    "    if sample < 1:\n",
    "        df = df.sample(frac=sample, random_state=42)\n",
    "\n",
    "    df[\"pickup_dt\"] = pd.to_datetime(df[\"pickup_datetime\"])\n",
    "    df[\"trip_time_min\"] = df[\"trip_time\"].astype(float) / 60\n",
    "    df[\"pickup_hour\"] = df[\"pickup_dt\"].dt.hour.astype(\"int8\")\n",
    "    df[\"pickup_dow\"] = df[\"pickup_dt\"].dt.dayofweek.astype(\"int8\")\n",
    "\n",
    "    df = df[(df[\"trip_miles\"] > 0) & (df[\"trip_miles\"] < 100)]\n",
    "    df = df[(df[\"trip_time_min\"] > 0) & (df[\"trip_time_min\"] < 240)]\n",
    "    df = df[df[\"base_passenger_fare\"] > 0]\n",
    "    df = df[df[\"tips\"].notna()]\n",
    "    return df\n",
    "\n",
    "\n",
    "def train(df, cont, cat, device, epochs=5, batch=4096, lr=1e-3):\n",
    "    tr, va = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler().fit(tr[cont])\n",
    "    dtr = TaxiDataset(tr, cont, cat, scaler)\n",
    "    dva = TaxiDataset(va, cont, cat, scaler)\n",
    "    tldr = DataLoader(dtr, batch_size=batch, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    vldr = DataLoader(dva, batch_size=batch * 2, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "    model = TipModel(dtr.cardinalities, len(cont)).to(device)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    loss = nn.L1Loss()\n",
    "    best = 1e9\n",
    "    for ep in range(epochs):\n",
    "        model.train(); s = 0\n",
    "        for x, c, y in tldr:\n",
    "            x, c, y = x.to(device), c.to(device), y.to(device)\n",
    "            opt.zero_grad(); l = loss(model(x, c), y); l.backward(); opt.step(); s += l.item() * len(y)\n",
    "        tr_mae = s / len(dtr)\n",
    "        model.eval(); s = 0\n",
    "        with torch.no_grad():\n",
    "            for x, c, y in vldr:\n",
    "                x, c, y = x.to(device), c.to(device), y.to(device)\n",
    "                s += loss(model(x, c), y).item() * len(y)\n",
    "        va_mae = s / len(dva)\n",
    "        print(f\"{ep+1}/{epochs} train {tr_mae:.2f} val {va_mae:.2f}\")\n",
    "        if va_mae < best:\n",
    "            best = va_mae; torch.save(model.state_dict(), \"tip_model.pt\")\n",
    "    print(\"best\", best)\n",
    "\n",
    "\n",
    "def cli(argv=None):\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--data-dir\", default=\"data\")\n",
    "    p.add_argument(\"--sample-frac\", type=float, default=0.2)\n",
    "    p.add_argument(\"--epochs\", type=int, default=5)\n",
    "    p.add_argument(\"--batch\", type=int, default=4096)\n",
    "    p.add_argument(\"--lr\", type=float, default=1e-3)\n",
    "    args, _ = p.parse_known_args(argv)\n",
    "\n",
    "    paths = list_files(pathlib.Path(args.data_dir))\n",
    "    if not paths:\n",
    "        raise SystemExit(\"No Parquet files found in \" + args.data_dir)\n",
    "\n",
    "    df = preprocess(paths, args.sample_frac)\n",
    "\n",
    "    cont = [\n",
    "        \"trip_miles\",\n",
    "        \"trip_time_min\",\n",
    "        \"base_passenger_fare\",\n",
    "        \"tolls\",\n",
    "        \"bcf\",\n",
    "        \"sales_tax\",\n",
    "        \"congestion_surcharge\",\n",
    "    ]\n",
    "    cat = [\n",
    "        \"PULocationID\",\n",
    "        \"DOLocationID\",\n",
    "        \"hvfhs_license_num\",\n",
    "        \"dispatching_base_num\",\n",
    "        \"shared_request_flag\",\n",
    "        \"wav_request_flag\",\n",
    "        \"pickup_hour\",\n",
    "        \"pickup_dow\",\n",
    "    ]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    train(df, cont, cat, device, epochs=args.epochs, batch=args.batch, lr=args.lr)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cli()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pad-final-project-uFfiJNJD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
