{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d00808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc, os, random, warnings, time\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import optuna, mlflow, mlflow.catboost\n",
    "from catboost import CatBoostRegressor, Pool, cv\n",
    "from mlflow.models import infer_signature\n",
    "from optuna.integration.mlflow import MLflowCallback\n",
    "from optuna.pruners import HyperbandPruner\n",
    "import optuna.exceptions as optuna_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2e2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=optuna_w.ExperimentalWarning)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "DATA_DIR = Path(\"data_sampled\")\n",
    "TARGET = \"tip_amount\"\n",
    "EXPERIMENT = \"YellowTaxi_OneTenthSample\"\n",
    "TRIALS = 1\n",
    "TIMEOUT_MIN = 108\n",
    "SPLITS = 3\n",
    "MAX_ITERS = 10_000\n",
    "EARLY_STOP = 350\n",
    "TUNE_FRACTION = 0.2\n",
    "TASK_TYPE, DEVICES = (\"CPU\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c21d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/03 16:14:25 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[I 2025-06-03 16:14:25,152] A new study created in memory with name: CatBoostOptunaStudy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac3554653ff429289d92551564bfb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n"
     ]
    }
   ],
   "source": [
    "def prep(f):\n",
    "    df = pl.read_parquet(f, low_memory=True)\n",
    "    for c in (\"tpep_pickup_datetime\",\"pickup_datetime\",\"tpep_dropoff_datetime\",\"dropoff_datetime\"):\n",
    "        if c in df.columns:\n",
    "            df = df.with_columns(pl.col(c).cast(pl.Datetime(\"ns\")))\n",
    "    df = df.filter(pl.col(TARGET) >= 0)\n",
    "    ns = 60_000_000_000\n",
    "    pick = next((c for c in (\"tpep_pickup_datetime\",\"pickup_datetime\") if c in df.columns), None)\n",
    "    drop = next((c for c in (\"tpep_dropoff_datetime\",\"dropoff_datetime\") if c in df.columns), None)\n",
    "    if pick and drop:\n",
    "        df = (df.with_columns(((pl.col(drop).cast(pl.Int64)-pl.col(pick).cast(pl.Int64))/ns)\n",
    "                              .cast(pl.Float32).alias(\"trip_duration_min\"))\n",
    "                .with_columns([\n",
    "                    pl.col(pick).dt.month().cast(pl.Int8).alias(\"pickup_month\"),\n",
    "                    pl.col(pick).dt.day().cast(pl.Int8).alias(\"pickup_day\"),\n",
    "                    pl.col(pick).dt.hour().cast(pl.Int8).alias(\"pickup_hour\"),\n",
    "                    pl.col(pick).dt.weekday().cast(pl.Int8).alias(\"pickup_dow\")])\n",
    "                .drop([pick, drop]))\n",
    "    else:\n",
    "        df = df.with_columns([\n",
    "            pl.lit(0).cast(pl.Float32).alias(\"trip_duration_min\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_month\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_day\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_hour\"),\n",
    "            pl.lit(0).cast(pl.Int8).alias(\"pickup_dow\")])\n",
    "    for c,t in {\"cbd_congestion_fee\":pl.Float32,\"airport_fee\":pl.Float32,\"congestion_surcharge\":pl.Float32}.items():\n",
    "        if c not in df.columns:\n",
    "            df = df.with_columns(pl.lit(0).cast(t).alias(c))\n",
    "    int_cats = [\"VendorID\",\"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"payment_type\",\n",
    "                \"pickup_month\",\"pickup_day\",\"pickup_hour\",\"pickup_dow\"]\n",
    "    for c in int_cats:\n",
    "        df = df.with_columns((pl.col(c).fill_null(-1) if c in df.columns else pl.lit(-1))\n",
    "                             .cast(pl.Int32).alias(c))\n",
    "    if \"store_and_fwd_flag\" not in df.columns:\n",
    "        df = df.with_columns(pl.lit(\"missing\").cast(pl.Utf8).alias(\"store_and_fwd_flag\"))\n",
    "    df = df.with_columns(pl.col(\"store_and_fwd_flag\").fill_null(\"missing\").cast(pl.Categorical))\n",
    "    return df\n",
    "\n",
    "ddf = pl.concat([prep(f) for f in sorted(DATA_DIR.glob(\"*.parquet\"))])\n",
    "pdf = ddf.to_pandas(use_pyarrow_extension_array=True)\n",
    "X = pdf.drop(columns=[TARGET])\n",
    "y = pdf[TARGET]\n",
    "cat_cols = [\"VendorID\",\"RatecodeID\",\"PULocationID\",\"DOLocationID\",\"payment_type\",\n",
    "            \"pickup_month\",\"pickup_day\",\"pickup_hour\",\"pickup_dow\",\"store_and_fwd_flag\"]\n",
    "for c in cat_cols:\n",
    "    X[c] = pd.Categorical(X[c].astype(\"string\").fillna(\"missing\")).codes.astype(\"int32\")\n",
    "num_cols = X.columns.difference(cat_cols)\n",
    "X[num_cols] = X[num_cols].fillna(0).astype(\"float32\")\n",
    "cat_idx = [X.columns.get_loc(c) for c in cat_cols]\n",
    "full_pool = Pool(X, y, cat_features=cat_idx)\n",
    "n_tune = int(TUNE_FRACTION * len(y))\n",
    "idx = np.random.choice(len(y), n_tune, replace=False)\n",
    "X_sub, y_sub = X.iloc[idx], y.iloc[idx]\n",
    "tune_pool = Pool(X_sub, y_sub, cat_features=cat_idx)\n",
    "input_example = X_sub.head(5)\n",
    "\n",
    "del ddf, pdf; gc.collect()\n",
    "mlflow.set_experiment(EXPERIMENT)\n",
    "if mlflow.active_run(): mlflow.end_run()\n",
    "mlflow.start_run(run_name=\"optuna_catboost\", log_system_metrics=True)\n",
    "start_tune = time.time()\n",
    "mlcb = MLflowCallback(metric_name=\"val_rmse\", create_experiment=False, mlflow_kwargs={\"nested\": True})\n",
    "pruner = HyperbandPruner(min_resource=500,  max_resource=MAX_ITERS, reduction_factor=4)\n",
    "\n",
    "def objective(trial):\n",
    "    mlflow.set_tag(\"mlflow.runName\", f\"trial_{trial.number}\")\n",
    "    params = {\n",
    "        \"loss_function\": \"RMSE\",\n",
    "        \"depth\": trial.suggest_int(\"depth\", 5, 7),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-3, 10, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.5, 1.0),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 1, 100),\n",
    "        \"bootstrap_type\": \"Bernoulli\",\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 1_000, MAX_ITERS, log=True),\n",
    "        \"early_stopping_rounds\": EARLY_STOP,\n",
    "        \"task_type\": TASK_TYPE,\n",
    "        \"devices\": DEVICES,\n",
    "        \"thread_count\": os.cpu_count(),\n",
    "        \"verbose\": False\n",
    "    }\n",
    "    cvd = cv(pool=tune_pool, params=params, fold_count=SPLITS,\n",
    "             partition_random_seed=SEED, early_stopping_rounds=EARLY_STOP,\n",
    "             verbose=False)\n",
    "    best_i = int(cvd[\"test-RMSE-mean\"].idxmin())\n",
    "    best_r = float(cvd[\"test-RMSE-mean\"].min())\n",
    "    mlflow.log_metric(\"rmse_cv\", best_r)\n",
    "    mlflow.log_metric(\"best_iterations\", best_i)\n",
    "    trial.set_user_attr(\"best_iterations\", best_i)\n",
    "    return best_r\n",
    "\n",
    "study = optuna.create_study(study_name=\"CatBoostOptunaStudy\", direction=\"minimize\",\n",
    "                            sampler=optuna.samplers.TPESampler(seed=SEED), pruner=pruner)\n",
    "study.optimize(objective, n_trials=TRIALS, timeout=TIMEOUT_MIN*60,\n",
    "               callbacks=[mlcb], show_progress_bar=True)\n",
    "tune_time = time.time() - start_tune\n",
    "print(f\"Tuning time: {tune_time:.2f}s\")\n",
    "\n",
    "print(\"Active MLflow run before final train:\", mlflow.active_run())\n",
    "while mlflow.active_run():\n",
    "    mlflow.end_run()\n",
    "print(\"Closed nested runs. Now active_run() is:\", mlflow.active_run())\n",
    "\n",
    "best = study.best_trial.params\n",
    "best_iter = study.best_trial.user_attrs[\"best_iterations\"]\n",
    "print(\"Best iteration chosen by CV:\", best_iter)\n",
    "final_params = {**best, \"iterations\": best_iter, \"random_seed\": SEED,\n",
    "                \"task_type\": \"CPU\", \"devices\": None,\n",
    "                \"thread_count\": os.cpu_count(), \"verbose\": False,\n",
    "                \"bootstrap_type\": \"Bernoulli\"}\n",
    "\n",
    "mlflow.start_run(run_name=\"final_catboost_fit\", log_system_metrics=True)\n",
    "start_train = time.time()\n",
    "model = CatBoostRegressor(**final_params).fit(full_pool, verbose=False)\n",
    "train_time = time.time() - start_train\n",
    "print(f\"Training time: {train_time:.2f}s\")\n",
    "\n",
    "start_log = time.time()\n",
    "sample_pred = model.predict(input_example)\n",
    "sig = infer_signature(input_example, sample_pred)\n",
    "mlflow.catboost.log_model(model, \"model\", signature=sig, input_example=input_example)\n",
    "mlflow.log_metric(\"best_rmse_cv\", study.best_value)\n",
    "mlflow.end_run()\n",
    "log_time = time.time() - start_log\n",
    "print(f\"Logging time: {log_time:.2f}s\")\n",
    "print(f\"{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')} - Total time: {tune_time+train_time+log_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 6))\n",
    "# sns.scatterplot(x=y_test, y=preds, alpha=0.3)\n",
    "# plt.xlabel(\"Actual\")\n",
    "# plt.ylabel(\"Predicted\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"scatter_actual_vs_pred.png\", dpi=300)\n",
    "\n",
    "# residuals = y_test - preds\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.histplot(residuals, bins=100, kde=True)\n",
    "# plt.xlabel(\"Residuals\")\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"residual_hist.png\", dpi=300)\n",
    "\n",
    "# importances = model.get_feature_importance(type=\"PredictionValuesChange\")\n",
    "# imp_df = pd.DataFrame({\"feature\": features, \"importance\": importances}).sort_values(\"importance\", ascending=False)\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.barplot(x=\"importance\", y=\"feature\", data=imp_df.head(20))\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"feature_importance.png\", dpi=300)\n",
    "\n",
    "# model.save_model(\"tip_model_catboost.cbm\")\n",
    "# imp_df.to_csv(\"feature_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95f731bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_sub' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset, DataDefinition, Report\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mevidently\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpresets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataDriftPreset\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ref_df = \u001b[43mX_sub\u001b[49m.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      5\u001b[39m prod_df = X.reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m schema = DataDefinition(\n\u001b[32m      8\u001b[39m     numerical_columns=[c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m X.columns \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m cat_cols],\n\u001b[32m      9\u001b[39m     categorical_columns=cat_cols\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'X_sub' is not defined"
     ]
    }
   ],
   "source": [
    "from evidently import Dataset, DataDefinition, Report\n",
    "from evidently.presets import DataDriftPreset\n",
    "\n",
    "ref_df = X_sub.reset_index(drop=True)\n",
    "prod_df = X.reset_index(drop=True)\n",
    "\n",
    "schema = DataDefinition(\n",
    "    numerical_columns=[c for c in X.columns if c not in cat_cols],\n",
    "    categorical_columns=cat_cols\n",
    ")\n",
    "\n",
    "eval_ref = Dataset.from_pandas(ref_df, data_definition=schema)\n",
    "eval_prod = Dataset.from_pandas(prod_df, data_definition=schema)\n",
    "\n",
    "report = Report([DataDriftPreset()], include_tests=True)\n",
    "eval_result = report.run(eval_prod, eval_ref)\n",
    "\n",
    "eval_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pad-final-project-uFfiJNJD-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
